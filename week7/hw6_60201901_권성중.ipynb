{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (768, 9)\n",
      "     0    1   2   3    4     5      6   7  8\n",
      "0    6  148  72  35    0  33.6  0.627  50  1\n",
      "1    1   85  66  29    0  26.6  0.351  31  0\n",
      "2    8  183  64   0    0  23.3  0.672  32  1\n",
      "3    1   89  66  23   94  28.1  0.167  21  0\n",
      "4    0  137  40  35  168  43.1  2.288  33  1\n",
      "5    5  116  74   0    0  25.6  0.201  30  0\n",
      "6    3   78  50  32   88  31.0  0.248  26  1\n",
      "7   10  115   0   0    0  35.3  0.134  29  0\n",
      "8    2  197  70  45  543  30.5  0.158  53  1\n",
      "9    8  125  96   0    0   0.0  0.232  54  1\n",
      "10   4  110  92   0    0  37.6  0.191  30  0\n",
      "11  10  168  74   0    0  38.0  0.537  34  1\n",
      "12  10  139  80   0    0  27.1  1.441  57  0\n",
      "13   1  189  60  23  846  30.1  0.398  59  1\n",
      "14   5  166  72  19  175  25.8  0.587  51  1\n",
      "15   7  100   0   0    0  30.0  0.484  32  1\n",
      "16   0  118  84  47  230  45.8  0.551  31  1\n",
      "17   7  107  74   0    0  29.6  0.254  31  1\n",
      "18   1  103  30  38   83  43.3  0.183  33  0\n",
      "19   1  115  70  30   96  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv',header=None)\n",
    "print(\"shape:\",dataset.shape)\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1     2     3      4     5      6   7  8\n",
      "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
      "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
      "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
      "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
      "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
      "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
      "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
      "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
      "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
      "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
      "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
      "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
      "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
      "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
      "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
      "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
      "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
      "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
      "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
      "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1\n",
      "nan으로 치환된 데이터 셀의 개수 :  652\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "cell_0_count = len(dataset[dataset[1]==0]) + len(dataset[dataset[2]==0]) + len(dataset[dataset[3]==0]) + len(dataset[dataset[4]==0]) + len(dataset[dataset[5]==0])\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0,np.NaN)\n",
    "print(dataset.head(20))\n",
    "print(\"nan으로 치환된 데이터 셀의 개수 : \",cell_0_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>section2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>section1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>section2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>section1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>section0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>section2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>section1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>section2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>section1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>section1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    section2\n",
       "1    section1\n",
       "2    section2\n",
       "3    section1\n",
       "4    section0\n",
       "..        ...\n",
       "763  section2\n",
       "764  section1\n",
       "765  section2\n",
       "766  section1\n",
       "767  section1\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv',header=None)\n",
    "dataset = dataset[0].map(lambda x:\"section0\" if x==0 else \"section1\" if x<3 else \"section2\")\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "374  1\n",
      "375  2\n",
      "376  0\n",
      "377  1\n",
      "378  2\n",
      "379  0\n",
      "380  1\n",
      "381  0\n",
      "382  1\n",
      "383  1\n",
      "384  1\n",
      "385  1\n",
      "386  2\n",
      "387  2\n",
      "388  2\n",
      "389  2\n",
      "390  1\n",
      "391  2\n",
      "392  1\n",
      "393  2\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "encoder = OneHotEncoder(categories=\"auto\")\n",
    "median = len(dataset)//2\n",
    "\n",
    "le_dataset = dataset.apply(le.fit_transform)\n",
    "print(le_dataset[median-10:median+10])\n",
    "print(type(le_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 2)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 1)\t1.0\n",
      "  (9, 1)\t1.0\n",
      "  (10, 1)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 2)\t1.0\n",
      "  (13, 2)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "  (15, 2)\t1.0\n",
      "  (16, 1)\t1.0\n",
      "  (17, 2)\t1.0\n",
      "  (18, 1)\t1.0\n",
      "  (19, 2)\t1.0\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "oh_dataset = encoder.fit_transform(le_dataset)\n",
    "print(oh_dataset[median-10:median+10])\n",
    "print(type(oh_dataset))\n",
    "\n",
    "oh_dataset = oh_dataset.toarray()\n",
    "print(oh_dataset[median-10:median+10])\n",
    "print(type(oh_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제 전\n",
      "(768, 9)\n",
      "삭제 후\n",
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "# d)\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv',header=None)\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0,np.NaN)\n",
    "print(\"삭제 전\")\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset.dropna(inplace=True)\n",
    "print(\"삭제 후\")\n",
    "print(dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "치환된 행\n",
      "      0      1          2         3           4     5      6   7  8\n",
      "0     6  148.0  72.000000  35.00000  155.548223  33.6  0.627  50  1\n",
      "1     1   85.0  66.000000  29.00000  155.548223  26.6  0.351  31  0\n",
      "2     8  183.0  64.000000  29.15342  155.548223  23.3  0.672  32  1\n",
      "5     5  116.0  74.000000  29.15342  155.548223  25.6  0.201  30  0\n",
      "7    10  115.0  72.405184  29.15342  155.548223  35.3  0.134  29  0\n",
      "..   ..    ...        ...       ...         ...   ...    ...  .. ..\n",
      "761   9  170.0  74.000000  31.00000  155.548223  44.0  0.403  43  1\n",
      "762   9   89.0  62.000000  29.15342  155.548223  22.5  0.142  33  0\n",
      "764   2  122.0  70.000000  27.00000  155.548223  36.8  0.340  27  0\n",
      "766   1  126.0  60.000000  29.15342  155.548223  30.1  0.349  47  1\n",
      "767   1   93.0  70.000000  31.00000  155.548223  30.4  0.315  23  0\n",
      "\n",
      "[376 rows x 9 columns]\n",
      "치환된 행의 개수 :  376\n"
     ]
    }
   ],
   "source": [
    "# e)\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv',header=None)\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0,np.NaN)\n",
    "\n",
    "replace_index = set()\n",
    "\n",
    "for column in dataset.columns:\n",
    "    mean = dataset[column].mean()\n",
    "    for index, row in enumerate(dataset[column]):\n",
    "        if pd.isna(row):\n",
    "            replace_index.add(index)\n",
    "            dataset.loc[index,column] = mean\n",
    "    \n",
    "print(\"치환된 행\")\n",
    "print(dataset.loc[list(replace_index)])\n",
    "print(\"치환된 행의 개수 : \",len(replace_index) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f)\n",
    "import csv\n",
    "dataset2 = dataset.copy()\n",
    "\n",
    "isp = dataset2[8] == 1\n",
    "isn = dataset2[8] == 0\n",
    "p_dataset = dataset2[isp]\n",
    "n_dataset = dataset2[isn]\n",
    "\n",
    "train_p =  p_dataset.sample(n=50,replace=False)\n",
    "train_p_index = train_p.index\n",
    "p_dataset = p_dataset.drop(train_p_index)\n",
    "test_p = p_dataset.sample(n=50,replace=False)\n",
    "train_n =  n_dataset.sample(n=50,replace=False)\n",
    "train_n_index = train_n.index\n",
    "n_dataset = n_dataset.drop(train_n_index)\n",
    "test_n = n_dataset.sample(n=50,replace=False)\n",
    "\n",
    "trainset = pd.concat([train_p,train_n], ignore_index=True)\n",
    "testset = pd.concat([test_p,test_n], ignore_index=True)\n",
    "\n",
    "trainset.to_csv(\"trainset.csv\",mode='w')\n",
    "trainset.to_csv(\"testset.csv\",mode=\"w\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
