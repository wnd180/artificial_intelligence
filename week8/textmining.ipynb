{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터의 문서 수: 25000\n",
      "학습 데이터의 문서 수: 25000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"/Users/wnd180/Downloads/aclImdb/train\")\n",
    "reviews_test = load_files(\"/Users/wnd180/Downloads/aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br /\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br /\", b\" \") for doc in text_test]\n",
    "\n",
    "print(\"학습 데이터의 문서 수: {}\".format(len(text_train)))\n",
    "print(\"학습 데이터의 문서 수: {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 샘플 수 (학습 데이터): [12500 12500]\n",
      "클래스별 샘플 수 (테스트 데이터): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"클래스별 샘플 수 (학습 데이터): {}\".format(np.bincount(y_train)))\n",
    "print(\"클래스별 샘플 수 (테스트 데이터): {}\".format(np.bincount(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 개수:74849\n",
      "첫 20개의 특성:\n",
      "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features_names = vect.get_feature_names()\n",
    "print(\"특성 개수:{}\".format(len(features_names)))\n",
    "print(\"첫 20개의 특성:\\n{}\".format(features_names[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20010에서 20030까지의 특성:\n",
      "['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
      "매 2000번째 특성:\n",
      "['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bête', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
     ]
    }
   ],
   "source": [
    "print(\"20010에서 20030까지의 특성:\\n{}\".format(features_names[20010:20030]))\n",
    "print(\"매 2000번째 특성:\\n{}\".format(features_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수: 318\n",
      "불용어 일부:\n",
      "['thin', 'any', 'within', 'afterwards', 'toward', 're', 'less', 'indeed', 'herself', 'else', 'six', 'why', 'fill', 'more', 'almost', 'too', 'much', 'twelve', 'a', 'she']\n"
     ]
    }
   ],
   "source": [
    "# 불용어 제거\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"불용어 개수: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "#english_stop_words는 frozenset 클래스 -> 리스트로 변환해야 함.\n",
    "\n",
    "print(\"불용어 일부:\\n{}\".format(list(ENGLISH_STOP_WORDS)[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어가 제거된 x_train: \n",
      "<25000x26966 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 2149958 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"불용어가 제거된 x_train: \\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term:['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "\n",
      "[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]\n",
      " [0.         0.27230147 0.         0.27230147 0.         0.85322574\n",
      "  0.22262429 0.         0.27230147]\n",
      " [0.55280532 0.         0.         0.         0.55280532 0.\n",
      "  0.28847675 0.55280532 0.        ]\n",
      " [0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "\n",
    "vect1 = CountVectorizer().fit(corpus)\n",
    "tf = vect1.transform(corpus)\n",
    "features_names = vect1.get_feature_names()\n",
    "print(\"Term:{}\".format(features_names[:]))\n",
    "print(tf.toarray())\n",
    "print()\n",
    "\n",
    "vect2 = TfidfVectorizer().fit(corpus)\n",
    "tfidf = vect2.transform(corpus)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘사전의 크기 13\n",
      "어휘사전 ['be', 'but', 'doth', 'fool', 'he', 'himself', 'is', 'knows', 'man', 'the', 'think', 'to', 'wise']\n",
      "변환된 데이터 [[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "bards_words = ['The fool doth think he is wise,', \n",
    "'but the wise man knows himself to be a fool']\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,1)).fit(bards_words)\n",
    "print(\"어휘사전의 크기\",len(cv.vocabulary_))\n",
    "print(\"어휘사전\",cv.get_feature_names())\n",
    "print(\"변환된 데이터\", cv.transform(bards_words).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘사전의 크기 14\n",
      "어휘사전 ['be fool', 'but the', 'doth think', 'fool doth', 'he is', 'himself to', 'is wise', 'knows himself', 'man knows', 'the fool', 'the wise', 'think he', 'to be', 'wise man']\n",
      "변환된 데이터 [[0 0 1 1 1 0 1 0 0 1 0 1 0 0]\n",
      " [1 1 0 0 0 1 0 1 1 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "cv2 = CountVectorizer(ngram_range=(2,2)).fit(bards_words)\n",
    "print(\"어휘사전의 크기\",len(cv2.vocabulary_))\n",
    "print(\"어휘사전\",cv2.get_feature_names())\n",
    "print(\"변환된 데이터\", cv2.transform(bards_words).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘사전의 크기 39\n",
      "어휘사전 ['be', 'be fool', 'but', 'but the', 'but the wise', 'doth', 'doth think', 'doth think he', 'fool', 'fool doth', 'fool doth think', 'he', 'he is', 'he is wise', 'himself', 'himself to', 'himself to be', 'is', 'is wise', 'knows', 'knows himself', 'knows himself to', 'man', 'man knows', 'man knows himself', 'the', 'the fool', 'the fool doth', 'the wise', 'the wise man', 'think', 'think he', 'think he is', 'to', 'to be', 'to be fool', 'wise', 'wise man', 'wise man knows']\n",
      "변환된 데이터 [[0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0\n",
      "  1 0 0]\n",
      " [1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1\n",
      "  1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "cv1to3 = CountVectorizer(ngram_range=(1,3)).fit(bards_words)\n",
    "print(\"어휘사전의 크기\",len(cv1to3.vocabulary_))\n",
    "print(\"어휘사전\",cv1to3.get_feature_names())\n",
    "print(\"변환된 데이터\", cv1to3.transform(bards_words).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘사전 크기 18\n",
      "어휘사전 [' ', ',', 'a', 'b', 'd', 'e', 'f', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 's', 't', 'u', 'w']\n",
      "변환된 데이터 [[6 1 0 0 1 3 1 4 3 1 1 0 1 3 2 3 0 1]\n",
      " [9 0 2 2 0 4 2 2 2 1 2 2 2 4 3 3 1 2]]\n"
     ]
    }
   ],
   "source": [
    "#char 로 해보기\n",
    "analyzer = CountVectorizer(analyzer=\"char\").fit(bards_words)\n",
    "print(\"어휘사전 크기\", len(analyzer.vocabulary_))\n",
    "print(\"어휘사전\", analyzer.get_feature_names())\n",
    "print(\"변환된 데이터\", analyzer.transform(bards_words).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "puthonli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "example_words = ['python','pythoner','pythoning','pythoned','puthonly']\n",
    "for stem in example_words:\n",
    "    print(ps.stem(stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'important', 'to', 'be', 'very', 'pythonly', 'while', 'you', 'are', 'pythoning', 'with', 'python']\n",
      "it\n",
      "is\n",
      "import\n",
      "to\n",
      "be\n",
      "veri\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "new_text =  \"It is important to be very pythonly while you are pythoning with python\"\n",
    "\n",
    "words = word_tokenize(new_text)\n",
    "print(words)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
